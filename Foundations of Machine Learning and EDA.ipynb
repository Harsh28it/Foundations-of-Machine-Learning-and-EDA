{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab6838c-fe18-474a-ba74-7e75f9fad6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 1 : What is the difference between AI, ML, DL, and Data Science? Provide a brief explanation of each.\n",
    "(Hint: Compare their scope, techniques, and applications for each.)\n",
    "    - *Artificial Intelligence (AI):* The broad field aiming to create systems capable of intelligent behavior like reasoning and decision-making. Includes rule-based systems and learning algorithms.\n",
    "- *Machine Learning (ML):* A subset of AI focused on algorithms that learn from data and improve over time without explicit programming.\n",
    "- *Deep Learning (DL):* A specialized subset of ML using neural networks to analyze complex data patterns, requiring large datasets and high computational power.\n",
    "- *Data Science:* A broader field that encompasses statistics, data analysis, and often AI techniques to extract insights from data for decision-making and prediction.\n",
    "| Aspect         | AI                             | ML                                    | DL                              | Data Science                    |\n",
    "|----------------|---------------------------     |----------------------------           |-------------------------------- |--------------------------------|\n",
    "| Scope          | Broad, all intelligent systems | Subset of AI for data-driven learning | Subset of ML with neural nets   | Interdisciplinary (stats, ML, domain) |\n",
    "| Techniques     | Rule-based, ML algorithms      | Regression, trees, clustering         | Neural networks (CNN, RNN)      | Statistics, visualization, ML   |\n",
    "| Data Needs     | Can be small (rule-based)      | Moderate structured data              | Large datasets                  | Depends on problem              |\n",
    "| Applications   | Robotics, expert systems       | Fraud detection, recommendations      | Image recognition, NLP          | Business analytics, predictions |\n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "    Question 2: Explain overfitting and underfitting in ML. How can you detect and prevent them?\n",
    "Hint: Discuss bias-variance tradeoff, cross-validation, and regularization techniques.\n",
    "    - *Overfitting:* Model learns noise/details too well, performs poorly on new data (low bias, high variance).\n",
    "- *Underfitting:* Model too simple, cannot capture patterns, poor performance on training and test data (high bias, low variance).\n",
    "- *Detection/Prevention:* Use bias-variance tradeoff, K-fold cross-validation to validate models, and regularization (L1/L2) to penalize complexity, plus sufficient training data.\n",
    "\n",
    "    \n",
    "    Question 3:How would you handle missing values in a dataset? Explain at least three methods with examples.\n",
    "Hint: Consider deletion, mean/median imputation, and predictive modeling.\n",
    "    - *Deletion:* Remove rows or columns with missing values when small fraction is missing.\n",
    "- *Mean/Median Imputation:* Replace missing data with the mean or median to retain dataset size.\n",
    "- *Predictive Modeling:* Use models like KNN or regression to predict missing values based on other features.\n",
    "\n",
    "    \n",
    "    Question 4:What is an imbalanced dataset? Describe two techniques to handle it (theoretical + practical).\n",
    "Hint: Discuss SMOTE, Random Under/Oversampling, and class weights in models.\n",
    "    - *Definition:* Dataset where classes are not equally represented, causing bias in model.\n",
    "- *Techniques:*\n",
    "  - *SMOTE:* Synthetic Minority Over-sampling creates synthetic samples for minority class.\n",
    "  - *Random Over/Under Sampling:* Either replicates minority samples or removes majority samples.\n",
    "  - *Class Weights:* Adjust loss function to penalize errors on minority class more.\n",
    "\n",
    "\n",
    "    \n",
    "    Question 5: Why is feature scaling important in ML? Compare Min-Max scaling and Standardization.\n",
    "Hint: Explain impact on distance-based algorithms (e.g., KNN, SVM) and gradient descent.\n",
    "    \n",
    "- *Importance:* Ensures all features contribute equally; critical for distance-based algorithms (KNN, SVM) and gradient descent convergence.\n",
    "- *Comparison:*\n",
    "  - *Min-Max Scaling:* Rescales features to [1]; sensitive to outliers.\n",
    "  - *Standardization (Z-score):* Centers data to mean 0, std 1; better with outliers.\n",
    "\n",
    "\n",
    "    \n",
    "    Question 6: Compare Label Encoding and One-Hot Encoding. When would you prefer one over the other?\n",
    "Hint: Consider categorical variables with ordinal vs. nominal relationships.\n",
    "    - *Label Encoding:* Assigns numeric values to categories; suitable for ordinal data with intrinsic order.\n",
    "- *One-Hot Encoding:* Creates binary columns per category; good for nominal data without order.\n",
    "- *Preference:* For algorithms sensitive to numeric relationships, use one-hot for nominal and label for ordinal.\n",
    "\n",
    "    \n",
    "    Question 7: Google Play Store Dataset\n",
    "a). Analyze the relationship between app categories and ratings. Which categories have the highest/lowest average ratings, and what could be the possible reasons?\n",
    "Dataset: https://github.com/MasteriNeuron/datasets.git (Include your Python code and output in the code box below.)\n",
    "   The analysis of average app ratings by category from the Google Play Store dataset reveals the following:\n",
    "\n",
    "Highest Average Ratings:\n",
    "- EVENTS (4.44)\n",
    "- EDUCATION (4.39)\n",
    "- ART_AND_DESIGN (4.36)\n",
    "- BOOKS_AND_REFERENCE (4.35)\n",
    "- PERSONALIZATION (4.34)\n",
    "\n",
    "Lowest Average Ratings:\n",
    "- DATING (3.97)\n",
    "- TOOLS (4.05)\n",
    "- MAPS_AND_NAVIGATION (4.05)\n",
    "- VIDEO_PLAYERS (4.06)\n",
    "- LIFESTYLE (4.09)\n",
    "\n",
    "Possible reasons for these patterns could be:\n",
    "- Highly rated categories like EVENTS, EDUCATION, and ART_AND_DESIGN tend to offer niche, specialized content or services that users find valuable and engaging, leading to better reviews.\n",
    "- BOOKS_AND_REFERENCE and PERSONALIZATION apps often enhance user experience or provide useful knowledge, which can increase satisfaction.\n",
    "- Lower ratings in categories like DATING might reflect user dissatisfaction due to unmet expectations, privacy concerns, or competitive market challenges.\n",
    "- TOOLS and MAPS_AND_NAVIGATION apps, which are utility-heavy, might receive critical reviews if they contain bugs, have poor UI, or fail at core functionalities.\n",
    "- VIDEO_PLAYERS and LIFESTYLE categories often face tough competition and varying user preferences, resulting in more varied and sometimes lower ratings.\n",
    "\n",
    "\n",
    "Question 8: Titanic Dataset a) Compare the survival rates based on passenger class (Pclass). Which class had the highest survival rate, and why do you think that happened?\n",
    "b) Analyze how age (Age) affected survival. Group passengers into children (Age < 18) and adults (Age ≥ 18). Did children have a better chance of survival?\n",
    "Dataset: https://github.com/MasteriNeuron/datasets.git (Include your Python code and output in the code box below.)\n",
    "  a) Survival rates by passenger class (Pclass) were:\n",
    "- 1st Class: 62.96%\n",
    "- 2nd Class: 47.28%\n",
    "- 3rd Class: 24.24%\n",
    "\n",
    "The highest survival rate was for 1st class passengers. This likely occurred because they had better access to lifeboats, cabins located closer to the deck, and overall preferential treatment during evacuation.\n",
    "\n",
    "b) Survival rates by age group showed:\n",
    "- Children (<18 years): 53.98%\n",
    "- Adults (≥18 years): 38.10%\n",
    "\n",
    "Children had a significantly better chance of survival, likely due to the \"women and children first\" evacuation protocol followed during the disaster.\n",
    "\n",
    "python\n",
    "# Survival rates by class\n",
    "survival_by_class = titanic_data.groupby('Pclass')['Survived'].mean()\n",
    "\n",
    "# Create age groups and survival by age group\n",
    "titanic_data['AgeGroup'] = titanic_data['Age'].apply(lambda x: 'Child' if x < 18 else 'Adult' if pd.notnull(x) else None)\n",
    "survival_by_age_group = titanic_data.groupby('AgeGroup')['Survived'].mean()\n",
    "\n",
    "print(survival_by_class)\n",
    "print(survival_by_age_group)\n",
    "\n",
    "\n",
    "\n",
    "Question 9: Flight Price Prediction Dataset\n",
    "a) How do flight prices vary with the days left until departure? Identify any exponential price surges and recommend the best booking window.\n",
    "b)Compare prices across airlines for the same route (e.g., Delhi-Mumbai). Which airlines are consistently cheaper/premium, and why?\n",
    "Dataset: https://github.com/MasteriNeuron/datasets.git (Include your Python code and output in the code box below.)\n",
    "   a) Flight Prices vs. Days Left Until Departure:\n",
    "- Prices are extremely high very close to departure (1-3 days), with the average price peaking at around 30,211 for 2 days left.\n",
    "- After about 10 days before departure, prices generally stabilize and tend to be lower, averaging around 19,000 - 20,000 from 15 to 50 days.\n",
    "- This shows an exponential price surge as the departure date approaches, especially in the last few days.\n",
    "- Recommendation: The best booking window for cheaper flights is around 15 to 50 days before departure, avoiding the last-minute surge.\n",
    "\n",
    "b) Price Comparison by Airlines for Delhi-Mumbai Route:\n",
    "- Cheaper airlines on average: AirAsia (~3981), Indigo (~4474), SpiceJet (~4628)\n",
    "- More premium/expensive airlines: GO_FIRST (~5762), Air_India (~23696), Vistara (~26630)\n",
    "- Low-cost carriers like AirAsia, Indigo, and SpiceJet offer cheaper prices likely due to business models focused on affordability.\n",
    "- Premium airlines such as Air India and Vistara typically charge more for better service, branding, and possibly full-service amenities.\n",
    "\n",
    "Python Code Summary:\n",
    "python\n",
    "# Price variation with days left\n",
    "days_price = flight_data.groupby('days_left')['price'].mean().reset_index()\n",
    "\n",
    "# Price comparison for Delhi-Mumbai flights\n",
    "route = flight_data[(flight_data['source_city'] == 'Delhi') & (flight_data['destination_city'] == 'Mumbai')]\n",
    "price_by_airline = route.groupby('airline')['price'].mean().sort_values()\n",
    "\n",
    "print(days_price)\n",
    "print(price_by_airline)\n",
    "\n",
    "\n",
    "\n",
    "Question 10: HR Analytics Dataset\n",
    "a). What factors most strongly correlate with employee attrition? Use visualizations to show key drivers (e.g., satisfaction, overtime, salary).\n",
    "b). Are employees with more projects more likely to leave?\n",
    "Dataset: hr_analytics\n",
    "   a) The factors that most strongly correlate with employee attrition (\"left\") are:\n",
    "\n",
    "- Satisfaction level (negative correlation, -0.39): Employees with lower satisfaction levels are much more likely to leave.\n",
    "- Time spent at the company (positive correlation, 0.14): Employees who have spent more time at the company tend to leave more.\n",
    "- Low salary (positive correlation, 0.13): Employees with a low salary are more likely to leave.\n",
    "- Work accidents (negative correlation, -0.15): Employees who have had work accidents are less likely to leave.\n",
    "- Promotion in the last 5 years (negative correlation, -0.06): Employees who received promotions recently are less likely to leave\n",
    "\n",
    "b) The correlation between number of projects and employee attrition is very small but positive (0.024), indicating that employees with more projects are very slightly more likely to leave, but this effect is weak compared to other factors like satisfaction and salary [attached data analysis]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
